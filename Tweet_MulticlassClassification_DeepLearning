# Gerekli Kütüphanelerin İçe Aktarılması
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, GRU, Dense, Dropout
from tensorflow.keras.layers import BatchNormalization


from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout

# Model parametrelerini tanımlama
embedding_dim = 128  # Gömme boyutu
max_length = max_length  # Maksimum dizi uzunluğu, sizin 'max_length' değerinize bağlı
vocab_size = vocab_size   # Sözlük büyüklüğü, verinize bağlı olarak ayarlayın

# LSTM modelini oluşturma
#model = Sequential()
#model.add(Embedding(vocab_size, embedding_dim, input_length=max_length))
#model.add(LSTM(64, return_sequences=True))
#model.add(Dropout(0.5))
#model.add(LSTM(32))
#model.add(Dense(16, activation='relu'))
#model.add(Dense(1, activation='softmax'))  # Çıkış katmanı

# GRU modelini oluşturma
model = Sequential()
model.add(Embedding(vocab_size, embedding_dim, input_length=max_length))
model.add(GRU(units=256))
model.add(Dropout(0.5))
model.add(Dense(16, activation='relu'))
model.add(Dropout(0.5))
model.add(BatchNormalization())
model.add(Dense(1, activation='sigmoid'))  # Örnek olarak 3 sınıflı çıktı katmanı


# Modeli derleme
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Modeli eğitme
history = model.fit(padded_train, yTrain, epochs=10, batch_size=32, validation_data=(padded_test, yTest))


# Model Performansının Değerlendirilmesi
import matplotlib.pyplot as plt

# Eğitim ve doğrulama kaybını çizme
plt.plot(history.history['loss'], label='Eğitim Kaybı')
plt.plot(history.history['val_loss'], label='Doğrulama Kaybı')
plt.title('Model Kaybı')
plt.ylabel('Kayıp')
plt.xlabel('Epoch')
plt.legend()
plt.show()

# Eğitim ve doğrulama doğruluğunu çizme
plt.plot(history.history['accuracy'], label='Eğitim Doğruluğu')
plt.plot(history.history['val_accuracy'], label='Doğrulama Doğruluğu')
plt.title('Model Doğruluğu')
plt.ylabel('Doğruluk')
plt.xlabel('Epoch')
plt.legend()
plt.show()

# Modeli test seti üzerinde değerlendirme
test_loss, test_accuracy = model.evaluate(padded_test, yTest)

print(f"Test Kaybı: {test_loss}")
print(f"Test Doğruluğu: {test_accuracy}")


import numpy as np
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Modelle tahmin yapma
predictions = model.predict(padded_test)

# Confusion matrisi hesaplama
cm = confusion_matrix(yTest, predicted_classes)

# Confusion matrisini görselleştirme
plt.figure(figsize=(10, 7))
sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=['Sınıf 1', 'Sınıf 2', 'Sınıf 3'], yticklabels=['Sınıf 1', 'Sınıf 2', 'Sınıf 3'])
plt.xlabel('Tahmin Edilen Sınıf')
plt.ylabel('Gerçek Sınıf')
plt.title('Confusion Matrisi')
plt.show()
